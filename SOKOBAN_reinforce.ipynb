{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "actor_critic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TLLlx9MDsLm",
        "outputId": "12d2b247-db5e-41ba-8cf4-b66218ec75f5"
      },
      "source": [
        "!pip install gym_sokoban"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym_sokoban\n",
            "  Downloading gym_sokoban-0.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tqdm>=4.32.1 in /usr/local/lib/python3.7/dist-packages (from gym_sokoban) (4.62.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from gym_sokoban) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.7/dist-packages (from gym_sokoban) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.2.3 in /usr/local/lib/python3.7/dist-packages (from gym_sokoban) (0.17.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from gym_sokoban) (2.23.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.2.3->gym_sokoban) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.2.3->gym_sokoban) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.2.3->gym_sokoban) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->gym_sokoban) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.2.3->gym_sokoban) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->gym_sokoban) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->gym_sokoban) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->gym_sokoban) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->gym_sokoban) (1.24.3)\n",
            "Installing collected packages: gym-sokoban\n",
            "Successfully installed gym-sokoban-0.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJxh1JNoL_OC"
      },
      "source": [
        "import argparse\n",
        "import gym\n",
        "import gym\n",
        "import gym_sokoban\n",
        "import numpy as np\n",
        "from itertools import count\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import math\n",
        "import random \n",
        "import pandas as pd \n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtE7zxPqi9go"
      },
      "source": [
        "image_transformations = T.Compose([\n",
        "                    T.ToPILImage(),\n",
        "                    T.Resize(64, interpolation= InterpolationMode.BILINEAR),\n",
        "                    T.ToTensor(),\n",
        "                    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                    ])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdDQhv6bfPsx"
      },
      "source": [
        "MAX_NUM_OF_ITERATIONS = 150\n",
        "seed = 999"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wodr19xdDxZl",
        "outputId": "eded80a2-812d-4c1a-ec67-3ffbfde5a51a"
      },
      "source": [
        "env = gym.make('PushAndPull-Sokoban-v2')\n",
        "\n",
        "env.max_steps =  MAX_NUM_OF_ITERATIONS\n",
        "screen = env.render(mode='rgb_array')\n",
        "env.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "num_of_actions = env.action_space.n\n",
        "num_of_actions"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "kdkcJEr1i4Li",
        "outputId": "10752ca8-a478-48e7-b069-38bf6515b11c"
      },
      "source": [
        "state_transformed = image_transformations(env.reset())\n",
        "plt.imshow(state_transformed.permute(1,2,0).detach().cpu().numpy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9ea14a6c2974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_transformations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_transformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_transformations' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlPcO4lHL8Lb",
        "outputId": "a44c7587-31ae-4cd5-ec80-5587ecd6b914"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ejhxyoEFVL"
      },
      "source": [
        "ActionLog = namedtuple('ActionLog', ['log_prob'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxVqBbfSEHM8"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_of_actions):\n",
        "        super().__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv1 = nn.Conv2d(3, 6, 7)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3)\n",
        "        self.pre_actions1 = nn.Linear(400, 200)\n",
        "        self.pre_actions2 = nn.Linear(200, 100)\n",
        "        self.actions = nn.Linear(100, num_of_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, 1) \n",
        "\n",
        "        actions = F.leaky_relu(self.pre_actions1(x))\n",
        "        actions = F.leaky_relu(self.pre_actions2(actions))\n",
        "        actions = F.leaky_relu(self.actions(actions))\n",
        "        actions = F.softmax(actions, dim=1)\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def init_weights(self):\n",
        "\n",
        "      torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.conv3.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.pre_actions1.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.pre_actions2.weight)\n",
        "\n",
        "      torch.nn.init.xavier_uniform_(self.actions.weight)\n",
        "\n",
        "  \n",
        "\n",
        "      return self\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, net):\n",
        "        self.net = net \n",
        "\n",
        "        self.saved_actions = []\n",
        "        self.rewards = []\n",
        "\n",
        "    def run_on_state(self, state):\n",
        "\n",
        "        state = state.to(device)\n",
        "        actions_prob = self.net(state)\n",
        "      \n",
        "        return  actions_prob\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaM_-uymNazL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzVf6Scad7ds"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbc1-WVnUOpf"
      },
      "source": [
        "GAMMA = 0.9\n",
        "EPS_START = 1.0\n",
        "EPS_END = 0.2\n",
        "EPS_DECAY = 6000\n",
        "steps_done = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZLpeWB8ELUr"
      },
      "source": [
        "def select_action(state, not_allowed_actions = None):\n",
        "  \n",
        "    global steps_done\n",
        "    steps_done += 1\n",
        "\n",
        "    state_tensor = image_transformations(state).unsqueeze(0)\n",
        "    probs = model.run_on_state(state_tensor)\n",
        "    categorical = Categorical(probs)\n",
        "\n",
        "    action = categorical.sample()\n",
        "\n",
        "    # while not_allowed_actions is not None and any(not_allowed_actions) and  action.item() in not_allowed_actions:\n",
        "    #   action = categorical.sample()\n",
        "\n",
        "\n",
        "\n",
        "    model.saved_actions.append(ActionLog(categorical.log_prob(action)))\n",
        "\n",
        "\n",
        "    return action.item()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8IhhbNIENpT"
      },
      "source": [
        "def train_on_episode():\n",
        "\n",
        "    saved_actions = model.saved_actions\n",
        "    policy_losses = [] \n",
        "    returns = []\n",
        "\n",
        "    step_total_r = 0\n",
        "    for step_immediate_rewars in reversed(model.rewards):\n",
        "        step_total_r = step_immediate_rewars + GAMMA * step_total_r\n",
        "        returns.insert(0, step_total_r)\n",
        "\n",
        "    returns = torch.tensor(returns).to(device)\n",
        "\n",
        "    returns = (returns - returns.mean()) / (returns.std() + eps)\n",
        "\n",
        "    prev_state = None\n",
        "    prev_action = None\n",
        "    for (saved_action, step_total_r) in zip(saved_actions, returns):\n",
        "\n",
        "        # policy_losses.append(-saved_action.log_prob * step_total_r)\n",
        "        policy_losses.append(-saved_action.log_prob * step_total_r)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    loss = torch.cat(policy_losses).sum()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    model.rewards = []\n",
        "    model.saved_actions = []\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIMSVv5DvIp9"
      },
      "source": [
        "net = Net(num_of_actions).init_weights().to(device)\n",
        "\n",
        "model = Agent(net)\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
        "\n",
        "eps = np.finfo(np.float32).eps.item()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "wtCNc3BlEQAT",
        "outputId": "be9c1d75-97b1-4e8c-8cfa-62656b76ae2d"
      },
      "source": [
        "episodes_durations = []\n",
        "steps_done = 0\n",
        "net.train()\n",
        "\n",
        "\n",
        "for episode_number in count(1):\n",
        "\n",
        "  if episode_number % 50 == 0:\n",
        "    print('episode_number {}'.format(episode_number))\n",
        "\n",
        "  state = env.reset()\n",
        "\n",
        "\n",
        "  #not_allowed_actions = None\n",
        "  for step_number in range(1, 10000):\n",
        "    #prev_state = state \n",
        "    action = select_action(state)\n",
        "  \n",
        "    state, reward, done, _ = env.step(action)\n",
        "    \n",
        "    # if prev_state is not None and np.array_equal(prev_state, state):\n",
        "    #   not_allowed_actions = not_allowed_actions if not_allowed_actions is not None else []\n",
        "\n",
        "    #   not_allowed_actions.append(action)\n",
        "\n",
        "    # else:\n",
        "    #   not_allowed_actions = None\n",
        "    \n",
        "    #prev_state = state\n",
        "\n",
        "    model.rewards.append(reward)\n",
        "\n",
        "    if done:\n",
        "      episodes_durations.append(step_number)\n",
        "      break\n",
        "\n",
        "  train_on_episode()\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c380894fd8f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#prev_state = state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6eb231695387>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(state, not_allowed_actions)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstate_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_transformations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_on_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_transformations' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "KTczNnZWUFq-",
        "outputId": "09332447-cee3-4ddd-d821-d94b8a69e406"
      },
      "source": [
        "\n",
        "durations_df = pd.DataFrame([(iteration, duration) for (iteration, duration) in enumerate(episodes_durations)], columns =[\"iteration\", \"duration\"])\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "sns.scatterplot(data=durations_df, x=\"iteration\", y=\"duration\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff0609ecd50>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEMCAYAAADXiYGSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df1RT9/0/8GcSIKAVY0AgoJXptzL8slZNWra1/XSFKnYidjvrZJy6zZ91Hlvtqi1jDpxSW9DROtFiW7tz1nnwM9ceW3AFXHFd67EWIrRNtdJZf1AJICAVUSPk3s8fjkxU8B1MuLnh+ThnZ8m9ed/7epnbPLk/cqORZVkGERHRTWiVLoCIiNSBgUFEREIYGEREJISBQUREQhgYREQkJEDpArxFkiR0dnYiMDAQGo1G6XKIiFRBlmV0dXVh+PDh0Gp771P4bWB0dnairq5O6TKIiFRp4sSJGDFiRK9pfhsYgYGBAK40HRQU5PZ4m82GhIQET5flE/y5N8C/+2Nv6qWW/i5fvoy6ujrXZ+jV/DYweg5DBQUFQa/XD2gZAx2nBv7cG+Df/bE39VJTfzc6lM+T3kREJISBQUREQhgYREQkhIFBRERC/Pak90BJkgx7SycuaUeh4cx5OCUZHRccCNDpcMnRjXBDCJySjPaOSwgb2f9jd8cZQ0NgCh8OALC3dKLt3MVbXu6NXnt1b56o3VuvHeg4Z1AY6k6dVWXtN3vtte+d6Dbjbj3eWm5/4xw6I7dLD9YTNvLKe6jVeu57aLo1a9as8djSfIjT6URzczMiIiIQECCWi5Ik48BnduS8egCfn2hHSFAA/lTyOUYM1+OP/1uLQ3XNCAkKwB92HMKho/0/dndcxcFT2PvxKXwreiRONnYg59UDt7zcvl7b05snavfWa29lHWGjRqi29pu99ur3TnSbcXcd3lruzcbZjnO79FQ9FR9feQ/HRIzAmIjb3Prycn+fnTwkdRV7SydeLD4ER5cTSebbsXNvHe6fPAb/u7eu1zSRx+6OAwBHlxNf1rdfV8NAlzsYtQ+Venytdne2GXfX4a3l+ur7peba+xrX8x6+WHwI9pZOj31GMjCu0nbuousfG5or/+Cu/796mshjd8f9hyTLnlvuYNQ+VOrxtdqvctNtxt11eGu5vvp+qbn2vsb9h6PLibaOi/AUBsZVjKEh0AfqXM97Ht9omshjd8cBgFaj8ehyB6P2oVKPr9XeQ2SbcXcd3lqur75faq69r3E9z40jQuApPIdxldtCAjEmYgSqDjehoeU8fvyD/4d91fVI+58J+OLEWdc0kcfujnNKMvSBOqTdPx73/P+oXjUMdLmDUftQqcfXandnm3F3Hd5arq++X2quva9xPe/hUz+bivhvGT12DkPjr7/p7XA4XPducefr+D1XSZ043YxvjYm4cuXBRQcCtDpcutyN8J4rE85fQlho/4/dHWcccc2VKR0Xb3m5N3rtqYYzrt48Ubu3XjvQcfbmVhhGjlRl7Td77bXvneg242493lpuf+Na2toRGzOa26WH6gkLHdhVUv19djIw+mC1WmE2m71QmfL8uTfAv/tjb+qllv76++zkOQwiIhLCwCAiIiEMDCIiEsLAICIiIQwMIiISwsAgIiIhDAwiIhIyaIGRl5eHpKQkxMXFoa6u7rr5hYWF182rra1FWloaUlJSMH/+fLS2tg5WuUREdI1BC4zk5GTs2LEDMTEx1837/PPPUVtb22ueJElYtWoVsrOzUV5eDovFgo0bNw5WuUREdI1BCwyLxQKTyXTd9MuXL2Pt2rW49pZWNpsNer0eFosFAJCeno6ysrLBKJWIiG5A8V/c27RpE9LS0jBmzJhe0+12O6Kjo13PjUYjJElCe3s7DAaD8PJtNtuAa7NarQMe6+v8uTfAv/tjb+ql9v4UDYyamhrYbDasXLnSa+vgvaSu58+9Af7dH3tTL7X013MvqRtRNDCqqqpw7NgxJCcnAwAaGxuxYMECPP/88zCZTGhoaHC9tq2tDVqt1q29CyIi8hxFA2Px4sVYvHix63lSUhKKioowceJESJKES5cuobq6GhaLBTt37sSMGTMUrJaIaGgbtMDIzc1FRUUFWlpaMG/ePBgMBuzZs6fP12u1WuTn5yMnJwcOhwMxMTHYsGHDYJVLRETXGLTAWL16NVavXt3vayorK3s9nzp1KkpKSrxZFhERCeI3vYmISAgDg4iIhDAwiIhICAODiIiEMDCIiEgIA4OIiIQwMIiISAgDg4iIhDAwiIhICAODiIiEMDCIiEgIA4OIiIQwMIiISAgDg4iIhDAwiIhICAODiIiEMDCIiEgIA4OIiIQwMIiISAgDg4iIhDAwiIhICAODiIiEDFpg5OXlISkpCXFxcairqwMAnD17FosWLUJKSgpmzZqFZcuWoa2tzTWmtrYWaWlpSElJwfz589Ha2jpY5RIR0TUGLTCSk5OxY8cOxMTEuKZpNBosXLgQ5eXlKCkpwdixY7Fx40YAgCRJWLVqFbKzs1FeXg6LxeKaR0REg2/QAsNiscBkMvWaZjAYkJiY6Ho+efJkNDQ0AABsNhv0ej0sFgsAID09HWVlZYNVLhERXSNA6QJ6SJKE4uJiJCUlAQDsdjuio6Nd841GIyRJQnt7OwwGg/BybTbbgGuyWq0DHuvr/Lk3wL/7Y2/qpfb+fCYw1q1bh2HDhuGxxx7z6HITEhKg1+vdHme1WmE2mz1ai6/w594A/+6PvamXWvpzOBx9/qHtE4GRl5eHkydPoqioCFrtlaNkJpPJdXgKANra2qDVat3auyAiIs9R/LLagoIC2Gw2bNmyBUFBQa7pCQkJuHTpEqqrqwEAO3fuxIwZM5Qqk4hoyBu0PYzc3FxUVFSgpaUF8+bNg8FgwEsvvYRt27YhNjYW6enpAIAxY8Zgy5Yt0Gq1yM/PR05ODhwOB2JiYrBhw4bBKpeIiK4xaIGxevVqrF69+rrpR48e7XPM1KlTUVJS4s2yiIhIkOKHpIiISB0YGEREJISBQUREQhgYREQkxCe+h0GAJMmwt3Si7dxFGENDYAofDq1Wo3RZREQuDAwfIEkyDnxmx4vFh+DockIfqMNTP5uK733HxNAgIp/BQ1I+wN7S6QoLAHB0OfFi8SHYWzoVroyI6L8YGD6g7dxFV1j0cHQ50dZxUaGKiIiux8DwAcbQEOgDdb2m6QN1MI4IUagiIqLrMTB8gCl8OJ762VRXaPScwzCFD1e4MiKi/+JJbx+g1Wrwve+YEGv6Ado6LsI4gldJ0c3xyjoabAwMH6HVahATcRtiIm5TuhRSAV5ZR0rgISkiFeKVdaQEBgaRCvHKOlICA4NIhXhlHSmBgUGkQryyjpTAk95EKsQr60gJDAwileKVdTTYeEiKiIiEMDCIiEgIA4OIiIQwMIiISMigBEZeXh6SkpIQFxeHuro61/Tjx49jzpw5SElJwZw5c3DixAmheURENPgGJTCSk5OxY8cOxMTE9Jqek5ODjIwMlJeXIyMjA9nZ2ULziIho8AlfVtve3o7XX38dR44cwYULF3rN27FjR79jLRbLddNaW1tx+PBh/OlPfwIApKamYt26dWhra4Msy33OMxqNoiUTEZEHCQfG008/jcuXL+Phhx9GSMit337AbrcjMjISOt2Vb6rqdDpERETAbrdDluU+5zEwiIiUIRwYNTU1+OijjxAUFOTNejzOZrMNeKzVavVgJb7Fn3sD/Ls/9qZeau9PODDi4uLQ2NiI22+/3SMrNplMaGpqgtPphE6ng9PpRHNzM0wmE2RZ7nOeuxISEqDX690eZ7VaYTab3R6nBv7cG+Df/bE39VJLfw6Ho88/tIUD47vf/S4WLlyIH//4xwgPD+817yc/+YnbRYWFhSE+Ph6lpaWYPXs2SktLER8f7zrk1N88IiIafMKBUV1djcjISOzfv7/XdI1Gc9PAyM3NRUVFBVpaWjBv3jwYDAbs2bMHa9asQWZmJrZu3YrQ0FDk5eW5xvQ3j4iIBp9wYLzxxhsDXsnq1auxevXq66ZPmDABu3btuuGY/uYREdHgc+tutd988w327duHpqYmREZG4sEHH8TIkSO9VRsREfkQ4S/u1dTUYNq0adi5cyeOHj2KnTt3Ytq0aaipqfFmfURE5COE9zDWr1+PnJwczJw50zXt73//O3Jzc/Hmm296pTgiIvIdwnsYJ06cwMMPP9xrWkpKCk6dOuXxooiIyPcIB8a4ceOwZ8+eXtPKysowduxYjxdFRES+R/iQVFZWFpYsWYI33ngD0dHROH36NE6ePImioiJv1kdERD5CODCmTp2KvXv34p///Ceam5vx4IMP4oEHHoDBYPBmfURE5CPcuqx25MiRmD17trdqISIiH9ZvYCxYsADbt28HAGRkZECj0dzwdTe7vTkREalfv4HxyCOPuB4/+uijXi+GiIh8V7+BMWvWLNfj8ePH46677rruNZ9++qnnqyIiIp8jfFntvHnzbjh94cKFHiuGiIh8101PekuSBFmWe/2vx6lTp1y/ikdERP7tpoExadIk18nuSZMm9Zqn1WqxZMkS71RGREQ+5aaB8d5770GWZcydOxd/+ctfXNM1Gg2MRiOCg4O9WiAREfmGmwZGTEwMAGDfvn1eL4aIiHyXW1/ce++991BVVYWzZ8/2OpeRn5/v8cKIiMi3CF8lVVhYiJycHEiShLKyMhgMBnz44YcIDQ31Zn1EROQjhAPjzTffxOuvv46srCwEBgYiKysLRUVF+Prrr71ZHxER+QjhwDh37hwmTpwIAAgMDERXVxfuvPNOVFVVea04IiLyHcLnMG6//XZ8+eWXuOOOO3DHHXeguLgYoaGh/E1vIqIhQjgwVqxYgfb2dgDAypUr8fTTT+PChQvIycnxWnFEROQ7hAJDkiQEBQW57iV15513Yu/evR4rYt++fdi0aZPrm+TLli3D9OnTcfz4cWRmZqK9vR0GgwF5eXmIjY312HqJiEic0DkMrVaLpUuXIigoyOMFyLKMZ555Bvn5+Xj77beRn5+PZ599FpIkIScnBxkZGSgvL0dGRgays7M9vn4iIhIjfNL77rvvRm1trXeK0GrR0dEBAOjo6EBERATOnj2Lw4cPIzU1FQCQmpqKw4cPo62tzSs1EBFR/4TPYURHR2PRokVITk5GVFRUrx9TWr58+YAL0Gg0eOmll7B06VIMGzYMnZ2deOWVV2C32xEZGem6uaFOp0NERATsdjuMRuOA10dERAMjHBgOhwMPPfQQAKCpqcljBXR3d2Pbtm3YunUrzGYzrFYrVqxY4bFvj9tstgGPtVqtHqnBF/lzb4B/98fe1Evt/QkHxvPPP++VAo4cOYLm5maYzWYAgNlsRkhICPR6PZqamuB0OqHT6eB0OtHc3AyTyeTW8hMSEqDX692uy2q1umryN/7cG+Df/bE39VJLfw6Ho88/tIUDo76+vs95Y8eOdb+q/4iKikJjYyO++uorjB8/HseOHUNrayvGjRuH+Ph4lJaWYvbs2SgtLUV8fDwPRxERKUQ4MKZNmwaNRtPrpoM95zGOHDky4AJGjx6NNWvWYPny5a7lrV+/HgaDAWvWrEFmZia2bt2K0NBQ5OXlDXg9RER0a4QD44svvuj1/MyZMygsLITFYrnlItLS0pCWlnbd9AkTJmDXrl23vHwiIrp1wpfVXmv06NH47W9/i4KCAk/WQ0REPmrAgQEAX331FS5evOipWoiIyIcJH5LKyMjo9d2Lixcv4t///jeWLl3qlcKIiMi3CAfGo48+2ut5SEgIvv3tb/PeTkREQ0S/gbFp06Z+Bx89ehTArX3Tm4iI1KHfwGhsbHQ9djgcqKioQEJCAmJiYtDQ0IDPPvsM06dP93qRRESkvH4D4+pvdz/11FP4wx/+gJSUFNe0iooKlJWVea86IiLyGcJXSf3rX/9y3UuqR1JSEt5//32PF0VERL5HODDGjRuHHTt29JpWXFyM22+/3eNFERGR7xG+Sio3NxfLli3Da6+9hsjISDQ1NSEgIACbN2/2Zn1EROQjhANj0qRJKC8vxyeffILm5maMHj0akydPRmBgoDfrIyIiHyEcGAAQGBjokXtHERGR+tzSrUGIiGjoYGAQEZEQBgYREQlhYBARkRAGBhERCWFgEBGREAYGEREJYWAQEZEQBgYREQlhYBARkRC3bg3iLQ6HA+vXr8eBAweg1+sxefJkrFu3DsePH0dmZiba29thMBiQl5fHn4QlIlKITwTGhg0boNfrUV5eDo1Gg5aWFgBATk4OMjIyMHv2bLz99tvIzs7Gn//8Z4WrJSIamhQ/JNXZ2Yndu3dj+fLl0Gg0AIDw8HC0trbi8OHDSE1NBQCkpqbi8OHDaGtrU7JcIqIhS/E9jPr6ehgMBhQWFuLgwYMYPnw4li9fjuDgYERGRkKn0wEAdDodIiIiYLfbYTQaFa6aiGjoUTwwnE4n6uvrMWnSJDz77LP45JNPsGTJEmzatMkjy7fZbAMea7VaPVKDL/Ln3gD/7o+9qZfa+1M8MEwmEwICAlyHnu666y6MGjUKwcHBaGpqgtPphE6ng9PpRHNzM0wmk1vLT0hIgF6vd7suq9UKs9ns9jg18OfeAP/uj72pl1r6czgcff6hrfg5DKPRiMTEROzfvx8AcPz4cbS2tiI2Nhbx8fEoLS0FAJSWliI+Pp6Ho4iIFKL4HgYA/P73v0dWVhby8vIQEBCA/Px8hIaGYs2aNcjMzMTWrVsRGhqKvLw8pUslIhqyfCIwxo4dizfeeOO66RMmTMCuXbsUqIiIiK6l+CEpIiJSBwYGEREJYWAQEZEQBgYREQlhYBARkRAGBhERCWFgEBGREAYGEREJYWAQEZEQBgYREQlhYBARkRAGBhERCWFgEBGREAYGEREJYWAQEZEQBgYREQlhYBARkRAGBhERCWFgEBGREAYGEREJYWAQEZEQBgYREQnxqcAoLCxEXFwc6urqAAC1tbVIS0tDSkoK5s+fj9bWVoUrJCIaunwmMD7//HPU1tYiJiYGACBJElatWoXs7GyUl5fDYrFg48aNCldJRDR0+URgXL58GWvXrsWaNWtc02w2G/R6PSwWCwAgPT0dZWVlClVIREQ+ERibNm1CWloaxowZ45pmt9sRHR3tem40GiFJEtrb25UokYhoyAtQuoCamhrYbDasXLnSK8u32WwDHmu1Wj1YiW/x594A/+6PvamX2vtTPDCqqqpw7NgxJCcnAwAaGxuxYMECzJ07Fw0NDa7XtbW1QavVwmAwuLX8hIQE6PV6t+uyWq0wm81uj1MDf+4N8O/+2Jt6qaU/h8PR5x/aih+SWrx4MT788ENUVlaisrISUVFR2L59OxYuXIhLly6huroaALBz507MmDFD4WqJiIYuxfcw+qLVapGfn4+cnBw4HA7ExMRgw4YNSpdFRDRk+VxgVFZWuh5PnToVJSUlClZDREQ9FD8kRURE6sDAICIiIQwMIiISwsAgIiIhDAwiIhLCwCAiIiEMDCIiEsLAICIiIQwMIiISwsAgIiIhDAwiIhLCwCAiIiEMDCIiEsLAICIiIQwMIiISwsAgIiIhDAwiIhLCwCAiIiE+9xOtRKQ8SZJhb+lE27mLMIaGwBQ+HFqtRumySGEMDCLqRZJkHPjMjheLD8HR5YQ+UIenfjYV3/uOiaExxPGQFBH1Ym/pdIUFADi6nHix+BDsLZ0KV0ZKY2AQUS9t5y66wqKHo8uJto6LClVEvkLxQ1Jnz57FM888g1OnTiEoKAjjxo3D2rVrYTQaUVtbi+zsbDgcDsTExGDDhg0ICwtTumQiv2YMDYE+UNcrNPSBOhhHhChYFfkCxfcwNBoNFi5ciPLycpSUlGDs2LHYuHEjJEnCqlWrkJ2djfLyclgsFmzcuFHpcon8nil8OJ762VToA3UA4DqHYQofrnBlpDTF9zAMBgMSExNdzydPnozi4mLYbDbo9XpYLBYAQHp6OpKTk/H8888rVSrRkKDVavC975gQa/oB2jouwjiCV0nRFYoHxtUkSUJxcTGSkpJgt9sRHR3tmmc0GiFJEtrb22EwGBSsksj/abUaxETchpiI25QuhXyITwXGunXrMGzYMDz22GPYu3evR5Zps9kGPNZqtXqkBl/kz70B/t0fe1MvtffnM4GRl5eHkydPoqioCFqtFiaTCQ0NDa75bW1t0Gq1bu9dJCQkQK/Xu12P1WqF2Wx2e5wa+HNvgH/3x97USy39ORyOPv/QVvykNwAUFBTAZrNhy5YtCAoKAnDlg/7SpUuorq4GAOzcuRMzZsxQskwioiFN8T2ML7/8Etu2bUNsbCzS09MBAGPGjMGWLVuQn5+PnJycXpfVEhGRMhQPjDvuuANHjx694bypU6eipKRkQMuVZRkAcPny5QHX5nA4BjzW1/lzb4B/98fe1EsN/fV8ZvZ8hl5NI99oqh/o6OhAXV2d0mUQEanSxIkTMWLEiF7T/DYwJElCZ2cnAgMDodHw+nEiIhGyLKOrqwvDhw+HVtv7NLffBgYREXmWT1wlRUREvo+BQUREQhgYREQkhIFBRERCGBhERCSEgUFEREIYGEREJISBcY3jx49jzpw5SElJwZw5c3DixAmlSxqws2fPYtGiRUhJScGsWbOwbNkytLW1AQBqa2uRlpaGlJQUzJ8/H62trQpXO3CFhYWIi4tzfbPfX3pzOBzIycnB9OnTMWvWLPzud78D4B/b6L59+/DII49g9uzZSEtLQ0VFBQB19paXl4ekpKRe2yDQfy9q7BMAIFMvc+fOlXfv3i3Lsizv3r1bnjt3rsIVDdzZs2fljz76yPX8hRdekH/zm9/ITqdTfuihh+SqqipZlmV5y5YtcmZmplJl3hKbzSYvWLBAfvDBB+WjR4/6VW/r1q2Tn3vuOVmSJFmWZfnMmTOyLKt/G5UkSbZYLPLRo0dlWZblI0eOyJMnT5adTqcqe6uqqpIbGhpc22CP/npRY5+yLMsMjKu0tLTIZrNZ7u7ulmVZlru7u2Wz2Sy3trYqXJlnlJWVyb/4xS/kTz75RJ45c6Zremtrqzx58mQFKxsYh8Mh//SnP5Xr6+td/7H6S2/nz5+XzWazfP78+V7T/WEblSRJvueee+Tq6mpZlmX5448/lqdPn6763q4OjP56UXOfit+t1pfY7XZERkZCp9MBAHQ6HSIiImC322E0GhWu7tb448/fbtq0CWlpaRgzZoxrmr/0Vl9fD4PBgMLCQhw8eBDDhw/H8uXLERwcrPptVKPR4KWXXsLSpUsxbNgwdHZ24pVXXvGr//7660WWZdX2yXMYQ8TVP3/rD2pqamCz2ZCRkaF0KV7hdDpRX1+PSZMm4a233sLKlSvxxBNP4MKFC0qXdsu6u7uxbds2bN26Ffv27cPLL7+MFStW+EVv/o57GFcxmUxoamqC0+mETqeD0+lEc3MzTCaT0qXdEm/9/K2SqqqqcOzYMSQnJwMAGhsbsWDBAsydO1f1vQFXtsWAgACkpqYCAO666y6MGjUKwcHBqt9Gjxw5gubmZtfPlZrNZoSEhECv16u+tx79fZbIsqzaPrmHcZWwsDDEx8ejtLQUAFBaWor4+Hif303sj7/+/O3ixYvx4YcforKyEpWVlYiKisL27duxcOFC1fcGXDmUlpiYiP379wO4clVNa2srYmNjVb+NRkVFobGxEV999RUA4NixY2htbcW4ceNU31uP/j5L1Pw5w9ubX+PYsWPIzMzEuXPnEBoairy8PIwfP17psgbkyy+/RGpqKmJjYxEcHAzgvz9/e+jQoet+/jY8PFzhigcuKSkJRUVFmDhxot/0Vl9fj6ysLLS3tyMgIAArVqzAAw884Bfb6DvvvINXX33V9Vs1Tz75JB566CFV9pabm4uKigq0tLRg1KhRMBgM2LNnT7+9qLFPgIFBRESCeEiKiIiEMDCIiEgIA4OIiIQwMIiISAgDg4iIhDAwiG5g5syZOHjwoCLrbmhowJQpU+B0OhVZP1FfeFktUT82b96MkydPYuPGjV5bR1JSEnJzc/H973/fa+sg8gTuYRB5UXd3t9IlEHkMA4PoBpKSkrBv3z5s27YN7777LqZMmYK0tDQAQEdHB7KysnDffffh/vvvx4svvug6fPTWW28hPT0d69evR2JiIjZv3oxTp07h5z//ORITE5GYmIinn34a586dAwCsWrUKDQ0NWLJkCaZMmYJXX30VX3/9NeLi4lxh09TUhCVLluCee+7BtGnT8Ne//tVV5+bNm7F8+XI888wzmDJlCmbOnInPPvtskP+1aKhgYBD1Qa/X4/HHH8fDDz+MmpoavPPOOwCAzMxMBAQEoKKiArt378b+/fuxa9cu17hPP/0UY8eOxf79+/GrX/0Ksizj8ccfxwcffIB3330XjY2N2Lx5MwBgw4YNiI6ORlFREWpqarBo0aLr6vj1r3+NqKgofPDBB/jjH/+IgoICHDhwwDW/srISM2fORHV1NZKSkrBu3Tov/8vQUMXAIHJDS0sL3n//fWRlZWHYsGEICwvDL3/5S+zZs8f1moiICMydOxcBAQEIDg7GuHHjcO+99yIoKAhGoxHz5s1DVVWV0PrsdjsOHTqElStXQq/XIz4+Ho8++ijefvtt12vMZjMeeOAB6HQ6zJ49G1988YXH+yYCeHtzIrc0NDSgu7sb9913n2uaJEm9bk0dFRXVa0xLSwuee+45VFdXo7OzE7IsIzQ0VGh9zc3NGDlyJG677TbXtOjoaNhsNtfzq2+sGBwcDIfDge7ubgQE8D9v8ixuUUT96Lmbao+oqCgEBQXho48+6vMD+doxBQUF0Gg0KCkpgcFgwD/+8Q+sXbtWaP0RERH45ptvcP78eVdo9PyaG9Fg4yEpon6EhYXh9OnTkCQJwJUP8HvvvRcvvPACzp8/D0mScOrUKXz88cd9LqOzsxPDhg3DiBEj0NTUhNdee63X/PDwcNTX199wrMlkwpQpU1BQUACHw4EvvvgCf/vb31wn4IkGEwODqB89P76UmJiIH/3oRwCA/Px8dHV14Yc//CHuvvtuPPnkkzhz5kyfy1i2bBkOHz4Mi8WCxYsXY/r06b3mL168GC+//DIsFgu2b99+3QuMmQEAAABXSURBVPiCggKcPn0a999/P5YtW4YnnniC39kgRfCLe0REJIR7GEREJISBQUREQhgYREQkhIFBRERCGBhERCSEgUFEREIYGEREJISBQUREQhgYREQk5P8AbpaX8iw+OIgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0QKeqnqCK6M"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQARuqlnAnk1"
      },
      "source": [
        "state = env.reset()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q20CbQb3r3bk",
        "outputId": "742eaf2a-771c-4f60-dd15-3825c4cad555"
      },
      "source": [
        "\n",
        "net.eval()\n",
        "net.to(device)\n",
        "state1 = image_transformations(state).unsqueeze(0).to(device)\n",
        "\n",
        "net(state1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0731, 0.0794, 0.0859, 0.0729, 0.0729, 0.0730, 0.0729, 0.0728, 0.0758,\n",
              "         0.0730, 0.0911, 0.0730, 0.0841]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GevOoTxi8DGy",
        "outputId": "39aacf9e-c452-4bab-8f20-76fcd6c385c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82254"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WreDG12Sys4m",
        "outputId": "58aee422-5c2a-4923-9bb9-7c7e22b5a41e"
      },
      "source": [
        "saved_actions = model.saved_actions\n",
        "policy_losses = [] \n",
        "returns = []\n",
        "\n",
        "step_total_r = 0\n",
        "for step_immediate_rewars in reversed(model.rewards):\n",
        "  step_total_r = step_immediate_rewars + GAMMA * step_total_r\n",
        "  returns.insert(0, step_total_r)\n",
        "\n",
        "returns = torch.tensor(returns).to(device)\n",
        "\n",
        "returns = (returns - returns.mean()) / (returns.std() + eps)\n",
        "\n",
        "for (saved_action, step_total_r) in zip(saved_actions, returns):\n",
        "  # policy_losses.append(-saved_action.log_prob * step_total_r)\n",
        "  policy_losses.append(saved_action.log_prob * step_total_r)\n",
        "\n",
        "   \n",
        "optimizer.zero_grad()\n",
        "  \n",
        "loss = torch.cat(policy_losses).sum()\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "model.rewards = []\n",
        "model.saved_actions = []    \n",
        "loss\n",
        "\n",
        "\n",
        "# loss = \n",
        "# loss"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.0550, device='cuda:0', grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iFmz9ws0C6N",
        "outputId": "4acee430-6e09-4633-92db-3c240f5c6945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "state1 = image_transformations(state).unsqueeze(0)\n",
        "probs = model.run_on_state(state1)\n",
        "probs\n",
        "# categorical = Categorical(probs)\n",
        "\n",
        "# action = categorical.sample()\n",
        "# action, probs, categorical.log_prob(action)\n",
        "\n",
        "# model.saved_actions.append(ActionLog(categorical.log_prob(action)))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.4675e-04, 8.2254e-01, 5.6333e-04, 5.5430e-04, 5.6239e-04, 5.4557e-04,\n",
              "         5.3103e-04, 7.9609e-04, 1.3101e-01, 5.6406e-04, 5.5700e-04, 4.0683e-02,\n",
              "         5.5461e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTdd4rTy1ReE"
      },
      "source": [
        "# [(a.log_prob, a.action) for a in saved_actions]"
      ],
      "execution_count": 154,
      "outputs": []
    }
  ]
}