{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "actor_critic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfuLYnwaSRVA",
        "outputId": "feb6925a-df4b-4799-9c18-7abe0b5231c8"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "\n",
        "!pip install box2d-py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 448 kB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9BSVI9uSS3a"
      },
      "source": [
        "import argparse\n",
        "import gym\n",
        "import gym\n",
        "import numpy as np\n",
        "from itertools import count\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import math\n",
        "import random \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "\n",
        "import gym\n",
        "from gym import wrappers\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ7Bi8kgUGud",
        "outputId": "e4110a01-4768-4c91-f87d-3463c6c51179"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi0I0rlzUHK2",
        "outputId": "f4ee3fad-1f17-4a90-e66b-5dd4a60bf1ca"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f0f39b7f8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtE7zxPqi9go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca05318-6521-474e-acca-65ac8b6e4bbb"
      },
      "source": [
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "state = env.reset()\n",
        "state"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00567808,  1.4207096 , -0.57515365,  0.43507355,  0.00658637,\n",
              "        0.13028093,  0.        ,  0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdDQhv6bfPsx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7ed83a9d-1fb5-45e0-a107-1dadfd29bb7a"
      },
      "source": [
        "# \n",
        "screen = env.render(mode='rgb_array')\n",
        "plt.imshow(screen)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0f1581d410>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEDxuutFU9Dw",
        "outputId": "898d36fd-feec-4bf0-be79-69a4624469d3"
      },
      "source": [
        "actions_map = {0: [0.5, 0.0], 1: [-1, -0.75] , 2: [-1, 0.75] , 3: [0.5, -0.75] , 4: [0.5, 0.75]}\n",
        "num_of_actions = len(actions_map)\n",
        "num_of_actions"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wodr19xdDxZl"
      },
      "source": [
        "ActionLog = namedtuple('ActionLog', ['log_prob'])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlPcO4lHL8Lb"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, state_size, num_of_actions):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.fc4 = nn.Linear(64, num_of_actions)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.fc1(state)\n",
        "        #x = self.bn1(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        #x = self.bn2(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.fc3(x)\n",
        "        #x = self.bn3(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x =  self.fc4(x)\n",
        "\n",
        "        return F.softmax(x, dim=1)\n",
        "    \n",
        "    def init_weights(self):\n",
        "\n",
        "      torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
        "\n",
        "      return self\n",
        "    \n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, net):\n",
        "        self.net = net \n",
        "\n",
        "        self.saved_actions = []\n",
        "        self.rewards = []\n",
        "\n",
        "    def run_on_state(self, state):\n",
        "\n",
        "        state = state.to(device)\n",
        "        actions_prob = self.net(state)\n",
        "      \n",
        "        return  actions_prob"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiT3RFYZWksR"
      },
      "source": [
        "GAMMA = 0.9\n",
        "EPS_START = 1.0\n",
        "EPS_END = 0.2\n",
        "EPS_DECAY = 6000\n",
        "steps_done = 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA0z-jLQWmxn"
      },
      "source": [
        "def select_action(state):\n",
        "  \n",
        "    global steps_done\n",
        "    steps_done += 1\n",
        "\n",
        "    state_tensor = torch.Tensor([state]).to(device)\n",
        "    probs = model.run_on_state(state_tensor)\n",
        "    categorical = Categorical(probs)\n",
        "\n",
        "    action = categorical.sample()\n",
        "    model.saved_actions.append(ActionLog(categorical.log_prob(action)))\n",
        "\n",
        "\n",
        "    return action.item()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWrNmUilWsuX"
      },
      "source": [
        "def train_on_episode():\n",
        "\n",
        "    saved_actions = model.saved_actions\n",
        "    policy_losses = [] \n",
        "    returns = []\n",
        "\n",
        "    step_total_r = 0\n",
        "    for step_immediate_rewars in reversed(model.rewards):\n",
        "        step_total_r = step_immediate_rewars + GAMMA * step_total_r\n",
        "        returns.insert(0, step_total_r)\n",
        "\n",
        "    returns = torch.tensor(returns).to(device)\n",
        "\n",
        "    returns = (returns - returns.mean()) / (returns.std() + eps)\n",
        "\n",
        "    prev_state = None\n",
        "    prev_action = None\n",
        "    for (saved_action, step_total_r) in zip(saved_actions, returns):\n",
        "\n",
        "        # policy_losses.append(-saved_action.log_prob * step_total_r)\n",
        "        policy_losses.append(-saved_action.log_prob * step_total_r)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    loss = torch.cat(policy_losses).sum()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    model.rewards = []\n",
        "    model.saved_actions = []\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2Lq32hqWvQ_"
      },
      "source": [
        "net = Net(state.shape[0] , num_of_actions).init_weights().to(device)\n",
        "\n",
        "model = Agent(net)\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
        "\n",
        "eps = np.finfo(np.float32).eps.item()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgbVd7mZggeJ"
      },
      "source": [
        "episodes_durations = []\n",
        "steps_done = 0\n",
        "net.train()\n",
        "\n",
        "\n",
        "for episode_number in count(1):\n",
        "\n",
        "  if episode_number > 5000:\n",
        "    break\n",
        "  if episode_number % 50 == 0:\n",
        "    print('episode_number {}'.format(episode_number))\n",
        "\n",
        "  state = env.reset()\n",
        "\n",
        "\n",
        "  #not_allowed_actions = None\n",
        "  for step_number in range(1, 10000):\n",
        "    action_id = select_action(state)\n",
        "\n",
        "    action = actions_map[action_id]\n",
        "\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    \n",
        "\n",
        "    model.rewards.append(reward)\n",
        "\n",
        "    if done:\n",
        "      episodes_durations.append(step_number)\n",
        "      break\n",
        "\n",
        "  train_on_episode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Me16IPXl5Iv",
        "outputId": "83e40486-d38f-4a33-bb60-59af5c7de9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# state_tensor = torch.Tensor(state).unsqueeze(0).to(device)\n",
        "\n",
        "# state_tensor.shape \n",
        "# #probs = model.run_on_state(state_tensor)\n",
        "# state = env.reset()\n",
        "state_tensor = torch.Tensor([state]).to(device)\n",
        "net(state_tensor).sum()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., device='cuda:0', grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKcA5LnsmJyt",
        "outputId": "14200aba-41a0-4b8d-fa50-f00963a47491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# net(state_tensor)\n",
        "fc1 = nn.Linear(8, 256)\n",
        "bn1 = nn.BatchNorm1d(256)\n",
        "fc2 = nn.Linear(256, 128)\n",
        "bn2 = nn.BatchNorm1d(128)\n",
        "fc3 = nn.Linear(128, 64)\n",
        "bn3 = nn.BatchNorm1d(64)\n",
        "fc4 = nn.Linear(64, 8)\n",
        "\n",
        "x = fc1(state_tensor)\n",
        "x = bn1(x)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-32c14388e5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         )\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2277\u001b[0m         )\n\u001b[1;32m   2278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     return torch.batch_norm(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256])"
          ]
        }
      ]
    }
  ]
}